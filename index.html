<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML//EN">
<HTML>
<HEAD>
	<TITLE>Welcome to Jiong Zhang's Home Page</TITLE>
	<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=iso-8859-1">
	<META NAME="GENERATOR" CONTENT="Mozilla/4.04j2 [en] (X11; I; SunOS 5.6 sun4u) [Netscape]">
	<meta name="keywords" contents="optimization, software, nonlinear programming, support vector machines"> 

<script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-43334914-1', 'utexas.edu');
  ga('send', 'pageview');
</script>
</HEAD>

<BODY TEXT="#000000" bgcolor="EBF5FB"  LINK="#0000FF" VLINK="#551A8B" ALINK="#FF0000">

<H1>
	Welcome to Jiong Zhang's Home Page</H1>
<table border="0" width="100%" cellspacing="0" cellpadding="0">
	<tr>
		<td>
      <h2 id="about-me">About me</h2>
			<p>My name is <b>Jiong Zhang</b>. I am a senior applied scientist at Amazon.
			My research focuses are large-scale machine learning, information retrieval and NLP.
			I am interested in developing methods that can efficiently leverage large language models in industry level applications, with extremely large data and output spaces.
			</p>

			<p>I received my Ph.D. from the <a href=http://bigdata.ices.utexas.edu/>Center of Big Data Analytics</a> of University of Texas at Austin
			supervised by <a href="https://www.cs.utexas.edu/users/inderjit/">Prof. Inderjit S. Dhillon</a>.
			Before that, I received my B.S. from <a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a>.
			<p>
			<p>
			E-Mail: zhangjiong724_AT_gmail.com
			</p>
		</td>
	</tr>
	</table>
	<HR>

<H2>
 Work Experience 
</H2>
<b>Amazon, Palo Alto, CA. (Apr 2020 - now) </b>
<UL>
	<LI>Senior Applied Scientist</LI>
	<LI>uild Amazon AI mode (natural language search) product search systems.</LI>
	<LI>Develop efficient ML models to handle extremely large output space.</LI>
	<LI>ork on optimizing Amazon product search engine, sponsored ads, and personalization.</LI>
</UL>

<b>A9.com (Amazon Search), Palo Alto, CA. (Apr 2018 - Dec 2018) & (May 2027 - Aug 2017) </b>
<UL>
	<LI>Applied Scientist Intern</LI>
	<LI>Develop deep learning models for inline search suggestion</LI>
	<LI>Develop efficient DNN training method via assistant network</LI>
</UL>

<b>The MathWorks, Natick, MA. (May 2016 - Aug 2016)</b>
<UL>
	<LI>Software Engineer Intern</LI>
	<LI>Develop maching learning toolbox for MATLAB</LI>
</UL>

<b>University of Texas at Austin, Austin, TX. (Sep 2014 - Apr 2020)</b>
<UL>
	<LI>Research Assistant</LI>
</UL>

<HR>

<H2>
 Software
</H2>
<b><a href=https://github.com/amzn/pecos>libpecos</a></b>
<UL>
	<LI>A versatile and modular ML framework for fast learning and inference on problems with large output
spaces.</LI>
	<LI>Over 280k downloads. Powered 20+ publications in top-tier conferences.</LI>
</UL>
<HR>


<H2>Publications</H2>
<ul>
  <li``>
    <p><a href="https://dl.acm.org/doi/pdf/10.1145/3616855.3635791">PEFA: Parameter-Free Adapters for Large-scale Embedding-based Retrieval Models</a>
<br />Wei-Cheng Chang, Jyun-Yu Jiang, Jiong Zhang, Mutasem Al-Darabsah, Choon Hui Teo, Cho-Jui Hsieh, Hsiang-Fu Yu and SVN Vishwanathan
<br />In <i>International Conference on Web Search and Data Mining (WSDM), 2024</i>.
  </li>
  
  <li>
    <p><a href="https://dl.acm.org/doi/pdf/10.1145/3589334.3645498">Entity disambiguation with extreme multi-label ranking</a>
<br />Jyun-Yu Jiang, Wei-Cheng Chang, Jiong Zhang, Cho-Jui Hsieh and Hsiang-Fu Yu
<br />In <i>ACM Web Conference (WWW), 2024</i>.
  </li>

  <li>
    <p><a href="https://assets.amazon.science/a6/95/2d01467e47c4bfe76e556369b0ce/build-faster-with-less-a-journey-to-accelerate-sparse-model-building-for-semantic-matching-in-product-search.pdf">Build faster with less: a journey to accelerate sparse model building for semantic matching in product search</a>
<br />Jiong Zhang, Yau-Shian Wang, Wei-Cheng Chang, Wei Li, Jyun-Yu Jiang, Cho-Jui Hsieh and Hsiang-Fu Yu
<br />In <i>International Conference on Information and Knowledge Management (CIKM), 2023</i>.
  </li>

  <li>
    <p><a href="https://proceedings.mlr.press/v202/tsai23a/tsai23a.pdf">Representer Point Selection for Explaining Regularized High-dimensional Models</a>
<br />Che-Ping Tsai, Jiong Zhang, Hsiang-Fu Yu, Eli Chien, Cho-Jui Hsieh and Pradeep Kumar Ravikumar
<br />In <i>International Conference on Machine Learning (ICML), 2023</i>.
  </li>

  <li>
    <p><a href="https://arxiv.org/pdf/2305.12349">PINA: Leveraging Side Information in eXtreme Multi-label Classification via Predicted Instance Neighborhood Aggregation</a>
<br />Eli Chien, Jiong Zhang, Cho-Jui Hsieh, Jyun-Yu Jiang, Wei-Cheng Chang, Olgica Milenkovic and Hsiang-Fu Yu
<br />In <i>International Conference on Machine Learning (ICML), 2023</i>.
  </li>

  <li>
    <p><a href="https://arxiv.org/pdf/2210.10160">Uncertainty in Extreme Multi-label Classification</a>
<br />Jyun-Yu Jiang, Wei-Cheng Chang, Jiong Zhong, Cho-Jui Hsieh and Hsiang-Fu Yu
<br />In <i>International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR), 2023</i>.
  </li>

  <li>
    <p><a href="https://assets.amazon.science/de/09/2a18243d45b282cbb0288800f26a/relevance-under-the-iceberg-reasonable-prediction-for-extreme-multi-label-classification.pdf">Relevance under the Iceberg: Reasonable Prediction for Extreme Multi-label Classification</a>
<br />Jyun-Yu Jiang, Wei-Cheng Chang, Jiong Zhang, Cho-Jui Hsieh and Hsiang-Fu Yu
<br />In <i>International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR), 2022</i>.
  </li>

  <li>
    <p><a href="https://www.jmlr.org/papers/volume23/21-0085/21-0085.pdf">PECOS: Prediction for Enormous and Correlated Output Spaces</a>
<br />Hsiang-Fu Yu, Kai Zhong, Jiong Zhang, Wei-Cheng Chang, and Inderjit Dhillon
<br />In <i>Journal of Machine Learning Research (JMLR), 2022</i>.
<br /><a href="https://github.com/amzn/pecos">[code]</a>
<a href="https://www.amazon.science/blog/amazon-open-sources-library-for-prediction-over-large-output-spaces">[blog]</a></p>
  </li>

  <li>
    <p><a href="https://arxiv.org/abs/2111.00064">Node Feature Extraction by Self-Supervised Multi-scale Neighborhood Prediction</a>
<br />Eli Chien, Wei-Cheng Chang, Cho-Jui Hsieh, Hsiang-Fu Yu, Jiong Zhang, Olgica Milenkovic and Inderjit Dhillon
<br />In <i>International Conference on Learning Representations (ICLR), 2022</i>.
<br /><a href="https://github.com/amzn/pecos/tree/mainline/examples/giant-xrt">[code]</a>
<span style="color: red;">(1st place on three OGB leaderboards as of 2021/11/08)</span></p>
  </li>

  <li>
    <p><a href="https://arxiv.org/abs/2110.00685">Fast Multi-Resolution Transformer Fine-tuning for Extreme Multi-label Text Classification</a>
<br />Jiong Zhang, Wei-Cheng Chang, Hsiang-Fu Yu and Inderjit Dhillon
<br />In <i>Advances in Neural Information Processing Systems (NeurIPS), 2021</i>.
<br /><a href="https://github.com/amzn/pecos/tree/mainline/examples/xr-transformer-neurips21">[code]</a>
<a href="https://www.amazon.science/blog/neurips-2021-amazon-pushes-the-boundaries-of-extreme-multilabel-classification">[blog]</a></p>
  </li>

  <li>
    <p><a href="https://arxiv.org/abs/2106.12657">Extreme Multi-Label Learning For Semantic Matching In Product Search</a>
<br />Wei-Cheng Chang, Daniel Jiang, Hsiang-Fu Yu, Choon Hui Teo, Jiong Zhang, Kai Zhong,
<br />Kedarnath Kolluri, Qie Hu, Nikhil Shandilya, Vyacheslav Ievgrafov, Japinder Singh, Inderjit Dhillon
<br />In <i>ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining (KDD), 2021</i>.
<br /><a href="https://github.com/amzn/pecos">[code]</a>
<a href="https://www.amazon.science/blog/applying-pecos-to-product-retrieval-and-text-autocompletion">[blog]</a></p>
  </li>

  <li>
    <p><a href="http://proceedings.mlr.press/v89/zhang19c/zhang19c.pdf">Extreme stochastic variational inference: Distributed inference for large scale mixture models</a>
<br />Jiong Zhang, Parameswaran Raman, Shihao Ji, Hsiang-Fu Yu, SVN Vishwanathan, Inderjit Dhillon
<br />In <i>International Conference on Artificial Intelligence and Statistics (AISTATS), 2019</i>.</p>
  </li>
  
  <li>
    <p><a href="https://proceedings.neurips.cc/paper/2019/file/9bd5ee6fe55aaeb673025dbcb8f939c1-Paper.pdf">Autoassist: A framework to accelerate training of deep neural networks</a>
<br />Jiong Zhang, Hsiang-Fu Yu, Inderjit Dhillon
<br />In <i>Advances in Neural Information Processing Systems (NeurIPS), 2019</i>.
  </li>
  
  <li>
    <p><a href="http://proceedings.mlr.press/v80/zhang18h/zhang18h.pdf">Learning Long Term Dependencies via Fourier Recurrent Units</a>
<br />Jiong Zhang, Yibo Lin, Zhao Song, Inderjit Dhillon
<br />In <i>International Conference on Machine Learning (ICML), 2018</i>.
  </li>
  
  <li>
    <p><a href="http://proceedings.mlr.press/v80/zhang18g/zhang18g.pdf">Stabilizing Gradients for Deep Neural Networks via Efficient SVD Parameterization</a>
<br />Jiong Zhang, Qi Lei, Inderjit Dhillon
<br />In <i>International Conference on Machine Learning (ICML), 2018</i>.
  </li>
  
  <li>
    <p><a href="http://proceedings.mlr.press/v54/zhang17b/zhang17b.pdf">Scalable Convex Multiple Sequence Alignment via Entropy-Regularized Dual Decomposition</a>
<br />Jiong Zhang, Ian EH Yen, Pradeep Ravikumar, Inderjit Dhillon
<br />In <i>International Conference on Artificial Intelligence and Statistics (AISTATS), 2017</i>.
  </li>
  
  <li>
    <p><a href="http://proceedings.mlr.press/v48/yena16.pdf">A convex atomic-norm approach to multiple sequence alignment and motif discovery</a>
<br />Ian En-Hsu Yen, Xin Lin, Jiong Zhang, Pradeep Ravikumar, Inderjit Dhillon
<br />In <i>International Conference on Machine Learning (ICML), 2017</i>.
  </li>

</ul>
<HR>
